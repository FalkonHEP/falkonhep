{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FalkonHEP: Density Ratio plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from falkonhep import LogFalkonHEPModel\n",
    "from falkonhep.utils import normalize_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 200000 # reference size\n",
    "B = 3000 # background expected size\n",
    "S = 0 # signal expected size\n",
    "\n",
    "\n",
    "reference_path = \"\" # directory containing reference files\n",
    "data_path = \"\" # directory containing data files\n",
    "out_path = \"\" # output directory\n",
    "\n",
    "features = [] # features used in model training\n",
    "prj_feature = '' # (generally high-level) feature\n",
    "\n",
    "normalize = True # if (training) data has to be normalized\n",
    "sig_type = 2 # (0: no signal, 1: separed, 2: mixed)\n",
    "weight = B / R\n",
    "\n",
    "bins = np.linspace(-200, 600, 10) #np.array([]) # how distributions are binned (specify the bin edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sigma' : 3.0, # length-scale of the Gaussian kernel\n",
    "    'penalty_list' : [1e-7], # list of regularization parameters\n",
    "    'iter_list' : [1000000], # list of maximum number of CG iterations\n",
    "    'M' : 10000, # number of Nystrom centers\n",
    "    'keops_active': \"auto\", # if pykeops is used to speed-up computations (optional, default \"no\")\n",
    "    'seed' : 12, # seed for Nystrom centers selection\n",
    "    'cg_tol' : np.sqrt(1e-7), # CG tolerance\n",
    "    'use_cpu' : False # if falkon will be executed in cpu (optional, default False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--] Training/test data prepared!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogFalkonHEPModel(reference_path, data_path, out_path)\n",
    "\n",
    "# seeds for reproducibility\n",
    "ref_seed = 12 \n",
    "data_seed = 13\n",
    "\n",
    "# Load data (non normalized): it will load both training and test features\n",
    "reference_set, data_set, bck_size, sig_size = model.generate_dataset(R, B, S, np.concatenate([features, [prj_feature]]), \n",
    "                                                                        normalize=False, \n",
    "                                                                        sig_type=sig_type,\n",
    "                                                                        cut=None, \n",
    "                                                                        ref_seed=ref_seed, \n",
    "                                                                        sig_seed=data_seed\n",
    "                                                                        )\n",
    "\n",
    "# Separe training reference/data \n",
    "reference_training, data_training = reference_set[:,:-1], data_set[:,:-1] \n",
    "if normalize:\n",
    "    reference_training, data_training = normalize_features(reference_set[:,:-1], data_set[:,:-1])\n",
    "reference_test, data_test = reference_set[:,-1], data_set[:,-1]\n",
    "\n",
    "print(\"[--] Training/test data prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model and make reference predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - penalty 1.000000e-07 - sub-iterations 1000000\n",
      "Stopping conjugate gradient descent at iteration 6. Solution has converged.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Falkon/LogFalkon model\n",
    "model.build_model(params,  weight)\n",
    "\n",
    "# Build training set \n",
    "Xtr = torch.from_numpy(np.vstack((reference_training, data_training)))\n",
    "ytr = torch.from_numpy(model.create_labels(reference_training.shape[0], data_training.shape[0]))\n",
    "\n",
    "# Fit the model\n",
    "model.fit(Xtr, ytr)\n",
    "\n",
    "# Make reference predictions\n",
    "ref_preds = np.squeeze(model.predict(reference_training))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build histograms and plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build histograms \n",
    "ref_weight = np.ones(reference_test.shape[0]) * (B/ R)\n",
    "ret_weight = np.exp(ref_preds) * (B / R)\n",
    "toy_weight = np.ones(data_test.shape[0]) \n",
    "\n",
    "ref_dd, _ = np.histogram(reference_test,  bins=bins, weights = ref_weight)\n",
    "pred_dd, _ = np.histogram(reference_test, bins=bins, weights = ret_weight)\n",
    "toy_dd, _ = np.histogram(data_test, bins=bins, weights = toy_weight)\n",
    "\n",
    "lr_toy = toy_dd / ref_dd \n",
    "lr_pred = pred_dd / ref_dd\n",
    "\n",
    "x = (bins[1:] + bins[:-1])/2\n",
    "\n",
    "# Plot and save results\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(x, lr_toy, 'o-', color='tomato', linewidth=2, label=\"Toy\")\n",
    "ax.plot(x, lr_pred, 'o-' ,color='royalblue', linewidth=2, label=\"Learned\")\n",
    "ax.set_title(r'Signal reconstruction', fontsize=20)\n",
    "ax.set_xlabel(r'$\\mathregular{t}$', fontsize=20)\n",
    "ax.set_ylabel(r'$\\mathregular{n(x|1)/n(x|0)}$', fontsize=20)\n",
    "ax.set_ylim(bottom=-1e-1, top=13) #set y lims to better observe results\n",
    "ax.legend(loc=\"best\", fontsize=14)\n",
    "\n",
    "plt.savefig(out_path + \"/dratio_{}_{}.pdf\".format(ref_seed, data_seed), transparent=True, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f26523b67ea2835ee6a77b36d2cc412a491957c6cdc7ecd6fb71972c20460352"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('mlenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
